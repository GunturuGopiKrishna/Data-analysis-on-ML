{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\gopia\\\\Desktop\\\\internship\\\\python codes'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\gopia\\\\Desktop\\\\internship\\\\datasets'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"C:/Users/gopia/Desktop/internship/datasets\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "data1=pd.read_csv('cancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0           M        17.99         10.38          122.80     1001.0   \n",
       "1           M        20.57         17.77          132.90     1326.0   \n",
       "2           M        19.69         21.25          130.00     1203.0   \n",
       "3           M        11.42         20.38           77.58      386.1   \n",
       "4           M        20.29         14.34          135.10     1297.0   \n",
       "..        ...          ...           ...             ...        ...   \n",
       "564         M        21.56         22.39          142.00     1479.0   \n",
       "565         M        20.13         28.25          131.20     1261.0   \n",
       "566         M        16.60         28.08          108.30      858.1   \n",
       "567         M        20.60         29.33          140.10     1265.0   \n",
       "568         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           0.2419  ...        25.380          17.33           184.60   \n",
       "1           0.1812  ...        24.990          23.41           158.80   \n",
       "2           0.2069  ...        23.570          25.53           152.50   \n",
       "3           0.2597  ...        14.910          26.50            98.87   \n",
       "4           0.1809  ...        22.540          16.67           152.20   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564         0.1726  ...        25.450          26.40           166.10   \n",
       "565         0.1752  ...        23.690          38.25           155.00   \n",
       "566         0.1590  ...        18.980          34.12           126.70   \n",
       "567         0.2397  ...        25.740          39.42           184.60   \n",
       "568         0.1587  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['id'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-b3b7827a9246>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Drop the first column as it is only an identifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3995\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3996\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3997\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3998\u001b[0m         )\n\u001b[0;32m   3999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3934\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3935\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3936\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3938\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3970\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5016\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5017\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5018\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5020\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['id'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#Drop the first column as it is only an identifier\n",
    "data1=data1.drop(['id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>Benign</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    Malignant        17.99         10.38          122.80     1001.0   \n",
       "1    Malignant        20.57         17.77          132.90     1326.0   \n",
       "2    Malignant        19.69         21.25          130.00     1203.0   \n",
       "3    Malignant        11.42         20.38           77.58      386.1   \n",
       "4    Malignant        20.29         14.34          135.10     1297.0   \n",
       "..         ...          ...           ...             ...        ...   \n",
       "564  Malignant        21.56         22.39          142.00     1479.0   \n",
       "565  Malignant        20.13         28.25          131.20     1261.0   \n",
       "566  Malignant        16.60         28.08          108.30      858.1   \n",
       "567  Malignant        20.60         29.33          140.10     1265.0   \n",
       "568     Benign         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           0.2419  ...        25.380          17.33           184.60   \n",
       "1           0.1812  ...        24.990          23.41           158.80   \n",
       "2           0.2069  ...        23.570          25.53           152.50   \n",
       "3           0.2597  ...        14.910          26.50            98.87   \n",
       "4           0.1809  ...        22.540          16.67           152.20   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564         0.1726  ...        25.450          26.40           166.10   \n",
       "565         0.1752  ...        23.690          38.25           155.00   \n",
       "566         0.1590  ...        18.980          34.12           126.70   \n",
       "567         0.2397  ...        25.740          39.42           184.60   \n",
       "568         0.1587  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign       357\n",
       "Malignant    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine the target variable ‘diagnosis’ which is the variable to predict\n",
    "#Get a count of diagnosis observations by type\n",
    "data1.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recode the target variable 'diagnosis' to contain the labels 'Malignant' and 'Benign'\n",
    "data1['diagnosis'].replace(['M','B'],['Malignant','Benign'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>Malignant</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>Benign</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    Malignant        17.99         10.38          122.80     1001.0   \n",
       "1    Malignant        20.57         17.77          132.90     1326.0   \n",
       "2    Malignant        19.69         21.25          130.00     1203.0   \n",
       "3    Malignant        11.42         20.38           77.58      386.1   \n",
       "4    Malignant        20.29         14.34          135.10     1297.0   \n",
       "..         ...          ...           ...             ...        ...   \n",
       "564  Malignant        21.56         22.39          142.00     1479.0   \n",
       "565  Malignant        20.13         28.25          131.20     1261.0   \n",
       "566  Malignant        16.60         28.08          108.30      858.1   \n",
       "567  Malignant        20.60         29.33          140.10     1265.0   \n",
       "568     Benign         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           0.2419  ...        25.380          17.33           184.60   \n",
       "1           0.1812  ...        24.990          23.41           158.80   \n",
       "2           0.2069  ...        23.570          25.53           152.50   \n",
       "3           0.2597  ...        14.910          26.50            98.87   \n",
       "4           0.1809  ...        22.540          16.67           152.20   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564         0.1726  ...        25.450          26.40           166.10   \n",
       "565         0.1752  ...        23.690          38.25           155.00   \n",
       "566         0.1590  ...        18.980          34.12           126.70   \n",
       "567         0.2397  ...        25.740          39.42           184.60   \n",
       "568         0.1587  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get summary of parameters\n",
    "x=data1.loc[:, ['radius_mean','area_mean','smoothness_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  area_mean  smoothness_mean\n",
       "0          17.99     1001.0          0.11840\n",
       "1          20.57     1326.0          0.08474\n",
       "2          19.69     1203.0          0.10960\n",
       "3          11.42      386.1          0.14250\n",
       "4          20.29     1297.0          0.10030\n",
       "..           ...        ...              ...\n",
       "564        21.56     1479.0          0.11100\n",
       "565        20.13     1261.0          0.09780\n",
       "566        16.60      858.1          0.08455\n",
       "567        20.60     1265.0          0.11780\n",
       "568         7.76      181.0          0.05263\n",
       "\n",
       "[569 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       radius_mean    area_mean  smoothness_mean\n",
       "count   569.000000   569.000000       569.000000\n",
       "mean     14.127292   654.889104         0.096360\n",
       "std       3.524049   351.914129         0.014064\n",
       "min       6.981000   143.500000         0.052630\n",
       "25%      11.700000   420.300000         0.086370\n",
       "50%      13.370000   551.100000         0.095870\n",
       "75%      15.780000   782.700000         0.105300\n",
       "max      28.110000  2501.000000         0.163400"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data1.iloc[:,1:31]\n",
    "y=data1.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Malignant\n",
       "1      Malignant\n",
       "2      Malignant\n",
       "3      Malignant\n",
       "4      Malignant\n",
       "         ...    \n",
       "564    Malignant\n",
       "565    Malignant\n",
       "566    Malignant\n",
       "567    Malignant\n",
       "568       Benign\n",
       "Name: diagnosis, Length: 569, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['diagnosis'].replace(['Malignant','Benign'],[1,0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6891891891891891"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(67-16)/74\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>1</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0            1        17.99         10.38          122.80     1001.0   \n",
       "1            1        20.57         17.77          132.90     1326.0   \n",
       "2            1        19.69         21.25          130.00     1203.0   \n",
       "3            1        11.42         20.38           77.58      386.1   \n",
       "4            1        20.29         14.34          135.10     1297.0   \n",
       "..         ...          ...           ...             ...        ...   \n",
       "564          1        21.56         22.39          142.00     1479.0   \n",
       "565          1        20.13         28.25          131.20     1261.0   \n",
       "566          1        16.60         28.08          108.30      858.1   \n",
       "567          1        20.60         29.33          140.10     1265.0   \n",
       "568          0         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           0.2419  ...        25.380          17.33           184.60   \n",
       "1           0.1812  ...        24.990          23.41           158.80   \n",
       "2           0.2069  ...        23.570          25.53           152.50   \n",
       "3           0.2597  ...        14.910          26.50            98.87   \n",
       "4           0.1809  ...        22.540          16.67           152.20   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564         0.1726  ...        25.450          26.40           166.10   \n",
       "565         0.1752  ...        23.690          38.25           155.00   \n",
       "566         0.1590  ...        18.980          34.12           126.70   \n",
       "567         0.2397  ...        25.740          39.42           184.60   \n",
       "568         0.1587  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52103744, 0.0226581 , 0.54598853, ..., 0.91202749, 0.59846245,\n",
       "        0.41886396],\n",
       "       [0.64314449, 0.27257355, 0.61578329, ..., 0.63917526, 0.23358959,\n",
       "        0.22287813],\n",
       "       [0.60149557, 0.3902604 , 0.59574321, ..., 0.83505155, 0.40370589,\n",
       "        0.21343303],\n",
       "       ...,\n",
       "       [0.45525108, 0.62123774, 0.44578813, ..., 0.48728522, 0.12872068,\n",
       "        0.1519087 ],\n",
       "       [0.64456434, 0.66351031, 0.66553797, ..., 0.91065292, 0.49714173,\n",
       "        0.45231536],\n",
       "       [0.03686876, 0.50152181, 0.02853984, ..., 0.        , 0.25744136,\n",
       "        0.10068215]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply normalization to rescale the features to a standard range of values.\n",
    "#Normalize the numeric variables from column2 to column 31 in the dataframe\n",
    "minmax=preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "minmax.fit(x).transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     569.000000\n",
       "mean      654.889104\n",
       "std       351.914129\n",
       "min       143.500000\n",
       "25%       420.300000\n",
       "50%       551.100000\n",
       "75%       782.700000\n",
       "max      2501.000000\n",
       "Name: area_mean, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['area_mean'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into Training set and Test set\n",
    "from sklearn import model_selection, neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>17.60</td>\n",
       "      <td>23.33</td>\n",
       "      <td>119.00</td>\n",
       "      <td>980.5</td>\n",
       "      <td>0.09289</td>\n",
       "      <td>0.20040</td>\n",
       "      <td>0.213600</td>\n",
       "      <td>0.100200</td>\n",
       "      <td>0.1696</td>\n",
       "      <td>0.07369</td>\n",
       "      <td>...</td>\n",
       "      <td>21.57</td>\n",
       "      <td>28.87</td>\n",
       "      <td>143.60</td>\n",
       "      <td>1437.0</td>\n",
       "      <td>0.12070</td>\n",
       "      <td>0.47850</td>\n",
       "      <td>0.51650</td>\n",
       "      <td>0.19960</td>\n",
       "      <td>0.2301</td>\n",
       "      <td>0.12240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>11.85</td>\n",
       "      <td>17.46</td>\n",
       "      <td>75.54</td>\n",
       "      <td>432.7</td>\n",
       "      <td>0.08372</td>\n",
       "      <td>0.05642</td>\n",
       "      <td>0.026880</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.05715</td>\n",
       "      <td>...</td>\n",
       "      <td>13.06</td>\n",
       "      <td>25.75</td>\n",
       "      <td>84.35</td>\n",
       "      <td>517.8</td>\n",
       "      <td>0.13690</td>\n",
       "      <td>0.17580</td>\n",
       "      <td>0.13160</td>\n",
       "      <td>0.09140</td>\n",
       "      <td>0.3101</td>\n",
       "      <td>0.07007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>12.05</td>\n",
       "      <td>22.72</td>\n",
       "      <td>78.75</td>\n",
       "      <td>447.8</td>\n",
       "      <td>0.06935</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.079430</td>\n",
       "      <td>0.029780</td>\n",
       "      <td>0.1203</td>\n",
       "      <td>0.06659</td>\n",
       "      <td>...</td>\n",
       "      <td>12.57</td>\n",
       "      <td>28.71</td>\n",
       "      <td>87.36</td>\n",
       "      <td>488.4</td>\n",
       "      <td>0.08799</td>\n",
       "      <td>0.32140</td>\n",
       "      <td>0.29120</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>0.09349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>12.49</td>\n",
       "      <td>16.85</td>\n",
       "      <td>79.19</td>\n",
       "      <td>481.6</td>\n",
       "      <td>0.08511</td>\n",
       "      <td>0.03834</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>0.006423</td>\n",
       "      <td>0.1215</td>\n",
       "      <td>0.05673</td>\n",
       "      <td>...</td>\n",
       "      <td>13.34</td>\n",
       "      <td>19.71</td>\n",
       "      <td>84.48</td>\n",
       "      <td>544.2</td>\n",
       "      <td>0.11040</td>\n",
       "      <td>0.04953</td>\n",
       "      <td>0.01938</td>\n",
       "      <td>0.02784</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>0.06174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>14.64</td>\n",
       "      <td>15.24</td>\n",
       "      <td>95.77</td>\n",
       "      <td>651.9</td>\n",
       "      <td>0.11320</td>\n",
       "      <td>0.13390</td>\n",
       "      <td>0.099660</td>\n",
       "      <td>0.070640</td>\n",
       "      <td>0.2116</td>\n",
       "      <td>0.06346</td>\n",
       "      <td>...</td>\n",
       "      <td>16.34</td>\n",
       "      <td>18.24</td>\n",
       "      <td>109.40</td>\n",
       "      <td>803.6</td>\n",
       "      <td>0.12770</td>\n",
       "      <td>0.30890</td>\n",
       "      <td>0.26040</td>\n",
       "      <td>0.13970</td>\n",
       "      <td>0.3151</td>\n",
       "      <td>0.08473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.039870</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>0.05955</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.13850</td>\n",
       "      <td>0.12660</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.073400</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>0.06777</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.41660</td>\n",
       "      <td>0.50060</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>15.13</td>\n",
       "      <td>29.81</td>\n",
       "      <td>96.71</td>\n",
       "      <td>719.5</td>\n",
       "      <td>0.08320</td>\n",
       "      <td>0.04605</td>\n",
       "      <td>0.046860</td>\n",
       "      <td>0.027390</td>\n",
       "      <td>0.1852</td>\n",
       "      <td>0.05294</td>\n",
       "      <td>...</td>\n",
       "      <td>17.26</td>\n",
       "      <td>36.91</td>\n",
       "      <td>110.10</td>\n",
       "      <td>931.4</td>\n",
       "      <td>0.11480</td>\n",
       "      <td>0.09866</td>\n",
       "      <td>0.15470</td>\n",
       "      <td>0.06575</td>\n",
       "      <td>0.3233</td>\n",
       "      <td>0.06165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>18.77</td>\n",
       "      <td>21.43</td>\n",
       "      <td>122.90</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>0.09116</td>\n",
       "      <td>0.14020</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.060900</td>\n",
       "      <td>0.1953</td>\n",
       "      <td>0.06083</td>\n",
       "      <td>...</td>\n",
       "      <td>24.54</td>\n",
       "      <td>34.37</td>\n",
       "      <td>161.10</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>0.14980</td>\n",
       "      <td>0.48270</td>\n",
       "      <td>0.46340</td>\n",
       "      <td>0.20480</td>\n",
       "      <td>0.3679</td>\n",
       "      <td>0.09870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>11.47</td>\n",
       "      <td>16.03</td>\n",
       "      <td>73.02</td>\n",
       "      <td>402.7</td>\n",
       "      <td>0.09076</td>\n",
       "      <td>0.05886</td>\n",
       "      <td>0.025870</td>\n",
       "      <td>0.023220</td>\n",
       "      <td>0.1634</td>\n",
       "      <td>0.06372</td>\n",
       "      <td>...</td>\n",
       "      <td>12.51</td>\n",
       "      <td>20.79</td>\n",
       "      <td>79.67</td>\n",
       "      <td>475.8</td>\n",
       "      <td>0.15310</td>\n",
       "      <td>0.11200</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.06548</td>\n",
       "      <td>0.2851</td>\n",
       "      <td>0.08763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "468        17.60         23.33          119.00      980.5          0.09289   \n",
       "293        11.85         17.46           75.54      432.7          0.08372   \n",
       "382        12.05         22.72           78.75      447.8          0.06935   \n",
       "315        12.49         16.85           79.19      481.6          0.08511   \n",
       "89         14.64         15.24           95.77      651.9          0.11320   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "170        12.32         12.39           78.85      464.1          0.10280   \n",
       "47         13.17         18.66           85.98      534.6          0.11580   \n",
       "414        15.13         29.81           96.71      719.5          0.08320   \n",
       "337        18.77         21.43          122.90     1092.0          0.09116   \n",
       "348        11.47         16.03           73.02      402.7          0.09076   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "468           0.20040        0.213600             0.100200         0.1696   \n",
       "293           0.05642        0.026880             0.022800         0.1875   \n",
       "382           0.10730        0.079430             0.029780         0.1203   \n",
       "315           0.03834        0.004473             0.006423         0.1215   \n",
       "89            0.13390        0.099660             0.070640         0.2116   \n",
       "..                ...             ...                  ...            ...   \n",
       "170           0.06981        0.039870             0.037000         0.1959   \n",
       "47            0.12310        0.122600             0.073400         0.2128   \n",
       "414           0.04605        0.046860             0.027390         0.1852   \n",
       "337           0.14020        0.106000             0.060900         0.1953   \n",
       "348           0.05886        0.025870             0.023220         0.1634   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "468                 0.07369  ...         21.57          28.87   \n",
       "293                 0.05715  ...         13.06          25.75   \n",
       "382                 0.06659  ...         12.57          28.71   \n",
       "315                 0.05673  ...         13.34          19.71   \n",
       "89                  0.06346  ...         16.34          18.24   \n",
       "..                      ...  ...           ...            ...   \n",
       "170                 0.05955  ...         13.50          15.64   \n",
       "47                  0.06777  ...         15.67          27.95   \n",
       "414                 0.05294  ...         17.26          36.91   \n",
       "337                 0.06083  ...         24.54          34.37   \n",
       "348                 0.06372  ...         12.51          20.79   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "468           143.60      1437.0           0.12070            0.47850   \n",
       "293            84.35       517.8           0.13690            0.17580   \n",
       "382            87.36       488.4           0.08799            0.32140   \n",
       "315            84.48       544.2           0.11040            0.04953   \n",
       "89            109.40       803.6           0.12770            0.30890   \n",
       "..               ...         ...               ...                ...   \n",
       "170            86.97       549.1           0.13850            0.12660   \n",
       "47            102.80       759.4           0.17860            0.41660   \n",
       "414           110.10       931.4           0.11480            0.09866   \n",
       "337           161.10      1873.0           0.14980            0.48270   \n",
       "348            79.67       475.8           0.15310            0.11200   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "468          0.51650               0.19960          0.2301   \n",
       "293          0.13160               0.09140          0.3101   \n",
       "382          0.29120               0.10920          0.2191   \n",
       "315          0.01938               0.02784          0.1917   \n",
       "89           0.26040               0.13970          0.3151   \n",
       "..               ...                   ...             ...   \n",
       "170          0.12420               0.09391          0.2827   \n",
       "47           0.50060               0.20880          0.3900   \n",
       "414          0.15470               0.06575          0.3233   \n",
       "337          0.46340               0.20480          0.3679   \n",
       "348          0.09823               0.06548          0.2851   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "468                  0.12240  \n",
       "293                  0.07007  \n",
       "382                  0.09349  \n",
       "315                  0.06174  \n",
       "89                   0.08473  \n",
       "..                       ...  \n",
       "170                  0.06771  \n",
       "47                   0.11790  \n",
       "414                  0.06165  \n",
       "337                  0.09870  \n",
       "348                  0.08763  \n",
       "\n",
       "[455 rows x 30 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468    1\n",
       "293    0\n",
       "382    0\n",
       "315    0\n",
       "89     0\n",
       "      ..\n",
       "170    0\n",
       "47     1\n",
       "414    1\n",
       "337    1\n",
       "348    0\n",
       "Name: diagnosis, Length: 455, dtype: int32"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.astype('int')\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>14.03</td>\n",
       "      <td>21.25</td>\n",
       "      <td>89.79</td>\n",
       "      <td>603.4</td>\n",
       "      <td>0.09070</td>\n",
       "      <td>0.06945</td>\n",
       "      <td>0.014620</td>\n",
       "      <td>0.01896</td>\n",
       "      <td>0.1517</td>\n",
       "      <td>0.05835</td>\n",
       "      <td>...</td>\n",
       "      <td>15.330</td>\n",
       "      <td>30.28</td>\n",
       "      <td>98.27</td>\n",
       "      <td>715.5</td>\n",
       "      <td>0.12870</td>\n",
       "      <td>0.15130</td>\n",
       "      <td>0.06231</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.07617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>27.42</td>\n",
       "      <td>26.27</td>\n",
       "      <td>186.90</td>\n",
       "      <td>2501.0</td>\n",
       "      <td>0.10840</td>\n",
       "      <td>0.19880</td>\n",
       "      <td>0.363500</td>\n",
       "      <td>0.16890</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040</td>\n",
       "      <td>31.37</td>\n",
       "      <td>251.20</td>\n",
       "      <td>4254.0</td>\n",
       "      <td>0.13570</td>\n",
       "      <td>0.42560</td>\n",
       "      <td>0.68330</td>\n",
       "      <td>0.26250</td>\n",
       "      <td>0.2641</td>\n",
       "      <td>0.07427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>9.72</td>\n",
       "      <td>18.22</td>\n",
       "      <td>60.73</td>\n",
       "      <td>288.1</td>\n",
       "      <td>0.06950</td>\n",
       "      <td>0.02344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1653</td>\n",
       "      <td>0.06447</td>\n",
       "      <td>...</td>\n",
       "      <td>9.968</td>\n",
       "      <td>20.83</td>\n",
       "      <td>62.25</td>\n",
       "      <td>303.8</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1909</td>\n",
       "      <td>0.06559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>10.51</td>\n",
       "      <td>23.09</td>\n",
       "      <td>66.85</td>\n",
       "      <td>334.2</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.06797</td>\n",
       "      <td>0.024950</td>\n",
       "      <td>0.01875</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.06556</td>\n",
       "      <td>...</td>\n",
       "      <td>10.930</td>\n",
       "      <td>24.22</td>\n",
       "      <td>70.10</td>\n",
       "      <td>362.7</td>\n",
       "      <td>0.11430</td>\n",
       "      <td>0.08614</td>\n",
       "      <td>0.04158</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.2227</td>\n",
       "      <td>0.06777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>12.81</td>\n",
       "      <td>13.06</td>\n",
       "      <td>81.29</td>\n",
       "      <td>508.8</td>\n",
       "      <td>0.08739</td>\n",
       "      <td>0.03774</td>\n",
       "      <td>0.009193</td>\n",
       "      <td>0.01330</td>\n",
       "      <td>0.1466</td>\n",
       "      <td>0.06133</td>\n",
       "      <td>...</td>\n",
       "      <td>13.630</td>\n",
       "      <td>16.15</td>\n",
       "      <td>86.70</td>\n",
       "      <td>570.7</td>\n",
       "      <td>0.11620</td>\n",
       "      <td>0.05445</td>\n",
       "      <td>0.02758</td>\n",
       "      <td>0.03990</td>\n",
       "      <td>0.1783</td>\n",
       "      <td>0.07319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>17.93</td>\n",
       "      <td>24.48</td>\n",
       "      <td>115.20</td>\n",
       "      <td>998.9</td>\n",
       "      <td>0.08855</td>\n",
       "      <td>0.07027</td>\n",
       "      <td>0.056990</td>\n",
       "      <td>0.04744</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.05510</td>\n",
       "      <td>...</td>\n",
       "      <td>20.920</td>\n",
       "      <td>34.69</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>0.13150</td>\n",
       "      <td>0.18060</td>\n",
       "      <td>0.20800</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>0.2504</td>\n",
       "      <td>0.07948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>21.09</td>\n",
       "      <td>26.57</td>\n",
       "      <td>142.70</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>0.11410</td>\n",
       "      <td>0.28320</td>\n",
       "      <td>0.248700</td>\n",
       "      <td>0.14960</td>\n",
       "      <td>0.2395</td>\n",
       "      <td>0.07398</td>\n",
       "      <td>...</td>\n",
       "      <td>26.680</td>\n",
       "      <td>33.48</td>\n",
       "      <td>176.50</td>\n",
       "      <td>2089.0</td>\n",
       "      <td>0.14910</td>\n",
       "      <td>0.75840</td>\n",
       "      <td>0.67800</td>\n",
       "      <td>0.29030</td>\n",
       "      <td>0.4098</td>\n",
       "      <td>0.12840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>11.06</td>\n",
       "      <td>17.12</td>\n",
       "      <td>71.25</td>\n",
       "      <td>366.5</td>\n",
       "      <td>0.11940</td>\n",
       "      <td>0.10710</td>\n",
       "      <td>0.040630</td>\n",
       "      <td>0.04268</td>\n",
       "      <td>0.1954</td>\n",
       "      <td>0.07976</td>\n",
       "      <td>...</td>\n",
       "      <td>11.690</td>\n",
       "      <td>20.74</td>\n",
       "      <td>76.08</td>\n",
       "      <td>411.1</td>\n",
       "      <td>0.16620</td>\n",
       "      <td>0.20310</td>\n",
       "      <td>0.12560</td>\n",
       "      <td>0.09514</td>\n",
       "      <td>0.2780</td>\n",
       "      <td>0.11680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>12.62</td>\n",
       "      <td>23.97</td>\n",
       "      <td>81.35</td>\n",
       "      <td>496.4</td>\n",
       "      <td>0.07903</td>\n",
       "      <td>0.07529</td>\n",
       "      <td>0.054380</td>\n",
       "      <td>0.02036</td>\n",
       "      <td>0.1514</td>\n",
       "      <td>0.06019</td>\n",
       "      <td>...</td>\n",
       "      <td>14.200</td>\n",
       "      <td>31.31</td>\n",
       "      <td>90.67</td>\n",
       "      <td>624.0</td>\n",
       "      <td>0.12270</td>\n",
       "      <td>0.34540</td>\n",
       "      <td>0.39110</td>\n",
       "      <td>0.11800</td>\n",
       "      <td>0.2826</td>\n",
       "      <td>0.09585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>20.55</td>\n",
       "      <td>20.86</td>\n",
       "      <td>137.80</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>0.10460</td>\n",
       "      <td>0.17390</td>\n",
       "      <td>0.208500</td>\n",
       "      <td>0.13220</td>\n",
       "      <td>0.2127</td>\n",
       "      <td>0.06251</td>\n",
       "      <td>...</td>\n",
       "      <td>24.300</td>\n",
       "      <td>25.48</td>\n",
       "      <td>160.20</td>\n",
       "      <td>1809.0</td>\n",
       "      <td>0.12680</td>\n",
       "      <td>0.31350</td>\n",
       "      <td>0.44330</td>\n",
       "      <td>0.21480</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>0.07569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "235        14.03         21.25           89.79      603.4          0.09070   \n",
       "461        27.42         26.27          186.90     2501.0          0.10840   \n",
       "192         9.72         18.22           60.73      288.1          0.06950   \n",
       "299        10.51         23.09           66.85      334.2          0.10150   \n",
       "179        12.81         13.06           81.29      508.8          0.08739   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "274        17.93         24.48          115.20      998.9          0.08855   \n",
       "181        21.09         26.57          142.70     1311.0          0.11410   \n",
       "507        11.06         17.12           71.25      366.5          0.11940   \n",
       "228        12.62         23.97           81.35      496.4          0.07903   \n",
       "535        20.55         20.86          137.80     1308.0          0.10460   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "235           0.06945        0.014620              0.01896         0.1517   \n",
       "461           0.19880        0.363500              0.16890         0.2061   \n",
       "192           0.02344        0.000000              0.00000         0.1653   \n",
       "299           0.06797        0.024950              0.01875         0.1695   \n",
       "179           0.03774        0.009193              0.01330         0.1466   \n",
       "..                ...             ...                  ...            ...   \n",
       "274           0.07027        0.056990              0.04744         0.1538   \n",
       "181           0.28320        0.248700              0.14960         0.2395   \n",
       "507           0.10710        0.040630              0.04268         0.1954   \n",
       "228           0.07529        0.054380              0.02036         0.1514   \n",
       "535           0.17390        0.208500              0.13220         0.2127   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "235                 0.05835  ...        15.330          30.28   \n",
       "461                 0.05623  ...        36.040          31.37   \n",
       "192                 0.06447  ...         9.968          20.83   \n",
       "299                 0.06556  ...        10.930          24.22   \n",
       "179                 0.06133  ...        13.630          16.15   \n",
       "..                      ...  ...           ...            ...   \n",
       "274                 0.05510  ...        20.920          34.69   \n",
       "181                 0.07398  ...        26.680          33.48   \n",
       "507                 0.07976  ...        11.690          20.74   \n",
       "228                 0.06019  ...        14.200          31.31   \n",
       "535                 0.06251  ...        24.300          25.48   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "235            98.27       715.5           0.12870            0.15130   \n",
       "461           251.20      4254.0           0.13570            0.42560   \n",
       "192            62.25       303.8           0.07117            0.02729   \n",
       "299            70.10       362.7           0.11430            0.08614   \n",
       "179            86.70       570.7           0.11620            0.05445   \n",
       "..               ...         ...               ...                ...   \n",
       "274           135.10      1320.0           0.13150            0.18060   \n",
       "181           176.50      2089.0           0.14910            0.75840   \n",
       "507            76.08       411.1           0.16620            0.20310   \n",
       "228            90.67       624.0           0.12270            0.34540   \n",
       "535           160.20      1809.0           0.12680            0.31350   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "235          0.06231               0.07963          0.2226   \n",
       "461          0.68330               0.26250          0.2641   \n",
       "192          0.00000               0.00000          0.1909   \n",
       "299          0.04158               0.03125          0.2227   \n",
       "179          0.02758               0.03990          0.1783   \n",
       "..               ...                   ...             ...   \n",
       "274          0.20800               0.11360          0.2504   \n",
       "181          0.67800               0.29030          0.4098   \n",
       "507          0.12560               0.09514          0.2780   \n",
       "228          0.39110               0.11800          0.2826   \n",
       "535          0.44330               0.21480          0.3077   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "235                  0.07617  \n",
       "461                  0.07427  \n",
       "192                  0.06559  \n",
       "299                  0.06777  \n",
       "179                  0.07319  \n",
       "..                       ...  \n",
       "274                  0.07948  \n",
       "181                  0.12840  \n",
       "507                  0.11680  \n",
       "228                  0.09585  \n",
       "535                  0.07569  \n",
       "\n",
       "[114 rows x 30 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33     1\n",
       "558    0\n",
       "466    0\n",
       "553    0\n",
       "435    1\n",
       "      ..\n",
       "326    0\n",
       "525    0\n",
       "416    0\n",
       "90     0\n",
       "489    1\n",
       "Name: diagnosis, Length: 114, dtype: int32"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test.astype('int')\n",
    "y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting Classifier to the Training set\n",
    "clf = neighbors.KNeighborsClassifier()\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the Test Set results\n",
    "y_pred=clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33     1\n",
       "558    0\n",
       "466    0\n",
       "553    0\n",
       "435    1\n",
       "      ..\n",
       "326    0\n",
       "525    0\n",
       "416    0\n",
       "90     0\n",
       "489    1\n",
       "Name: diagnosis, Length: 114, dtype: int32"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71,  3],\n",
       "       [ 4, 36]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build confusion matrix on Test and Train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "clf_cm_test = confusion_matrix(y_test,y_pred)\n",
    "clf_cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain accuracy\n",
    "accuracy = clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9385964912280702\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the probability of each test data point\n",
    "#Get the probability distribution\n",
    "probas = clf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize the probabilities\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(dpi=150)\n",
    "plt.hist(probas, bins=20)\n",
    "plt.title('Classification Probabilities')\n",
    "plt.xlabel('Probability')\n",
    "plt.ylabel('# of Instances')\n",
    "plt.xlim([0.5, 1.0])\n",
    "plt.legend(y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation\n",
    "1.For most instances, the classifier is very confident of its determination (note the tall bars at 0 and 1 on the x-axis).\n",
    "2.However, there are a number of instances where the classifier is less certain. In some cases, it’s nearly a coin toss (0.59 on the x-axis).\n",
    "3.The model is equally uncertain about both benign and malignant instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ROC curve for the model\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs =clf.predict_proba(x_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XmYFNXVx/HvAQUUEVEwRhZBwQUQESeAK66IK0QUUVRwI25RcYkmJnGJeXHXGHfRuIOKomDcFUWJiAiIgKIsCoMbIigKgwxz3j9ujdOMMz09w3RXd8/v8zz9TNfSVadruut03Vt1ytwdERGRytSLOwAREcluShQiIpKUEoWIiCSlRCEiIkkpUYiISFJKFCIikpQShaTMzAaZ2ctxx5FNzOxHM9s2hvW2NTM3sw0yve50MLNZZrZvDV6nz2QGKFHkKDP7zMxWRTuqr8zsATPbJJ3rdPdH3b13OteRyMz2MLPXzWyFmX1vZuPMrGOm1l9BPG+Y2WmJ49x9E3efn6b1bW9mT5rZt9H7n2FmF5hZ/XSsr6aihNV+fZbh7p3c/Y0q1vOr5Jjpz2RdpUSR245w902ArsCuwJ9jjqdGKvpVbGa7Ay8DzwJbA+2AD4CJ6fgFn22/zM1sO+BdYBGws7s3BY4BCoAmtbyu2N57tm13qYS765GDD+Az4MCE4euA/yYMNwRuABYCXwN3ARslTO8LTAd+AOYBfaLxTYH7gC+BxcDVQP1o2hDg7ej5XcAN5WJ6Frgger418BSwBFgAnJsw3xXAaOCRaP2nVfD+3gLuqGD8C8BD0fN9gULgL8C30TYZlMo2SHjtJcBXwMNAM+C5KOZl0fNW0fz/BNYCRcCPwG3ReAfaR88fAG4H/gusIOzot0uIpzcwB/geuAN4s6L3Hs37SOL/s4LpbaN1D47e37fAZQnTuwPvAMuj/+VtQIOE6Q6cDXwKLIjG/YuQmH4A3gf2Tpi/frSd50Xv7X2gNTAhWtZP0XY5Npr/cMLnaznwP6BLuc/uJcAMYDWwAQmf5yj2KVEcXwM3ReMXRuv6MXrsTsJnMpqnE/AK8F302r/E/V3Nh0fsAehRw3/cul+sVsCHwL8Spt8CjAU2J/wCHQcMj6Z1j3ZWBxGOKlsCO0bTngHuBhoDWwKTgT9E0375UgL7RDsVi4abAasICaJetCP5O9AA2BaYDxwczXsFsAboF827Ubn3tjFhp7xfBe/7ZODL6Pm+QDFwEyEp9Ip2WDuksA1KX3tt9NqNgC2A/tH6mwBPAs8krPsNyu3Y+XWi+C7avhsAjwKjomnNox3fUdG086JtUFmi+Ao4Ocn/v2207nuj2Hch7HR3iqbvBvSM1tUW+Ag4v1zcr0TbpjR5nhBtgw2AC6MYGkXTLiZ8xnYALFrfFuW3QTTcDfgG6EFIMIMJn9eGCZ/d6YREs1HCuNLP8zvAidHzTYCe5d7zBgnrGkLZZ7IJISleCDSKhnvE/V3Nh0fsAehRw39c+GL9SPh158BrwGbRNCPsMBN/ze5O2S/Hu4GbK1jmb6KdTeKRx3HA+Oh54pfSCL/w9omGTwdej573ABaWW/afgf9Ez68AJiR5b62i97RjBdP6AGui5/sSdvaNE6Y/AfwthW2wL/Bz6Y6wkji6AssSht+g6kQxImHaocDH0fOTgHcSphkh0VaWKNYQHeVVMr10p9kqYdxkYGAl858PjCkX9/5VfMaWAbtEz+cAfSuZr3yiuBP4R7l55gC9Ej67p1TweS5NFBOAK4HmlbznyhLFccC0dH7v6upD7YO5rZ+7v2pmvYDHCL9alwMtCL+K3zez0nmN8OsOwi+55ytY3jbAhsCXCa+rR9ihrcPd3cxGEb6cE4DjCc0lpcvZ2syWJ7ykPqE5qdSvlplgGVAC/Bb4uNy03xKaWX6Z191/Shj+nHBUU9U2AFji7kW/TDTbGLiZkIyaRaObmFl9d1+bJN5EXyU8X0n4RUwU0y/vOdp+hUmWs5TwXmu0PjPbnnCkVUDYDhsQjvISrfM/MLMLgdOiWB3YlPCZgvCZmZdCPBD+/4PN7I8J4xpEy61w3eWcClwFfGxmC4Ar3f25FNZbnRilGtSZnQfc/U3Cr9kbolHfEpqBOrn7ZtGjqYeObwhf0u0qWNQiwhFF84TXberunSpZ9UjgaDPbhnAU8VTCchYkLGMzd2/i7ocmhp3k/fxEaH44poLJAwhHT6WamVnjhOE2wBcpbIOKYriQ0LTSw903JTSvQUgwSWNOwZeEI6WwwJC9WlU+O68SmsFq6k5Cku0QvZe/UPY+Sv3yfsxsb0K/wQCgmbtvRmieLH1NZZ+ZiiwC/lnu/7+xu4+saN3lufun7n4coenzWmB09D+uavtXJ0apBiWK/HELcJCZdXX3EkLb9c1mtiWAmbU0s4Ojee8DTjazA8ysXjRtR3f/knCm0Y1mtmk0bbvoiOVX3H0aoeN3BPCSu5ceQUwGfjCzS8xsIzOrb2adzex31Xg/lxJ+lZ5rZk3MrJmZXU1oPrqy3LxXmlmDaGd3OPBkCtugIk0IyWW5mW0OXF5u+teE/paa+C+ws5n1i870ORvYKsn8lwN7mNn1ZrZVFH97M3vEzDZLYX1NCH0iP5rZjsCZKcxfTPh/bmBmfyccUZQaAfzDzDpY0MXMtoimld8u9wJnmFmPaN7GZnaYmaV0tpaZnWBmLaL/Yelnam0UWwmV/w+eA7Yys/PNrGH0uemRyjolOSWKPOHuS4CHCO3zEH4dzgUmmdkPhF+oO0TzTiZ0Ct9M+NX4JqG5AEJbegNgNqEJaDTJm0BGAgcSmr5KY1kLHEFo419A+HU/gnBGVarv523gYELn75eEJqVdgb3c/dOEWb+K4vyC0Hl8hruXNldVug0qcQuhY/hbYBLwYrnp/yIcQS0zs1tTfS/R+/mWcIR0HaFZqSPhzJ7Vlcw/j5AU2wKzzOx7whHbFEK/VFUuIjQHriDsuB+vYv6XCGeUfULY1kWs2zx0E6H/52VCArqPsK0g9Dk9aGbLzWyAu08h9FndRvjfzCX0JaSqD+E9/0jY5gPdvcjdVxLOPpsYratn4ovcfQXhBI0jCJ+LT4H9qrFeqUTpGSsiOSe6kvcRd0/WhJOVzKwe4fTcQe4+Pu54RJLREYVIhpjZwWa2mZk1pKzPYFLMYYlUKW2JwszuN7NvzGxmJdPNzG41s7lRaYJu6YpFJEvsTjgr51tC80g/d18Vb0giVUtb05OZ7UM4z/8hd+9cwfRDgT8SzjXvQbhYTB1PIiJZJm1HFO4+gXCVamX6EpKIu/skYDMzS+W8cRERyaA4L7hrybpnVRRG474sP6OZDQWGAjRu3Hi3HXfcMSMBioikyj08Skp+/Uh1fHVen2pjUBs+ZzOWM4Pib929RU3eW5yJovzFP1DJBTXufg9wD0BBQYFPmTIlnXGJSI5zh6IiWLWqeo+avKb0UVxc83gbNYKNNqrFRyMPfzc2fvvMnTT64Rua3XLF5zWNL85EUUi45L5UK8K58CKSZ9asyexOu6io6pgqs8EGyXfCm29eOzvz0uTQqBFYRT+ba2rxYjjzTDj2WBg0CHaNrrW85YoaLzLORDEWOCeqF9QD+D66MlhE0qikpPo74fXZaa9aBWtTrZRVgWQ72y22qN2d9kYbhUSRk9xhxAi46KKQmQ87rNYWnbZNYmYjCRU6m0fFzy4nFJzD3e8iFKU7lHDV5krClcIidYp75n9tr67wWvDUbLhh5Tvbxo2hefPa3Wk3bFjLv7bz1bx5cPrpMH487Lcf3HsvbFd7Za/Sliiiol7Jpjuh3o1I1igpqXlTR0133CUlNYvVLPkOt0WL2tthlz7qZ9VNWOUXH34I778P99wDp51W69k1Vw+ypA5wh59/zuxO++efax5vgwaV73SbNIEtt6zdHXeDBvq1XafNnAlTp8JJJ0G/fjB/fmiLSwMlCknZ2rWZ3WmvWpX6KYDl1auXfKe76aa1u9Nu1Ei/tiVDfv4Z/u//wuM3v4EBA8IHME1JApQocpZ7aGvO5E57zZqax9uwYeU73aZNYautaq95ZKONQlu6fm1L3nn3XTj1VJg1C044AW6+OXwJ0izvEkVxMdx9N3z9ddyRpKYmO/zSnX5Nf23Xr59857vZZrW7027UKPzCF5H1sHgx7L13OIp47rlaPaupKnmVKNauhcGD4bHHcuvXZLJf282awdZb195Ou/TXtojkiE8+ge23h5Yt4fHH4YADQttpBuVNoigpCWeHPfYYXHMNXHJJ3BGJiKyH5cvhT38K10a88Qbssw/8/vexhJIXicIdzjkH/vMfuOIKJQkRyXFjx4arq7/6Ci6+GH5XnbsI176cTxTucMEFcOedIUH8/e9xRyQish5OOw3uuw923hmefRYKCuKOKPcTxZVXwi23wHnnwfDhudU3ISIClJ2ZYhYSwzbbhF++DRrEG1ck5+6ZnVg9du3a0KdzyCHw5JNKEiKSgxYtgjPOgIED4cQT07YaM3vf3Wt0eJLTJy3OmQMrV0LfvkoSIpJjSkpCm3mnTqGzen2KcKVZTjc9TZsW/u66a7xxiIhUy6efhr6ICRPgwANDjaZ27eKOqlI5nSimTg3XC+iGdyKSU2bPhhkz4P77YciQrG8SyflE0aVLDtePF5G644MPYPr0cFVw376hiF+zZnFHlZKc7aNwD01P3brFHYmISBKrV8Pf/hbOZvrb38puv5cjSQJyOFEsWADff6/+CRHJYu+8E3ZSV18Nxx8fft1moIhfbcvZRpvSjmwdUYhIVlq8GHr1CqWRn38+nMefo3L2iGLq1FAFtXPnuCMREUnw0Ufhb8uW8MQToSR4DicJyOFEMW1aOP04B4/iRCQfLVsGp5wCHTvCW2+Fcf36hdsb5ricTRRTp6p/QkSyxJgxIUE89BD8+c+xF/GrbTnZR/Hll+HGROqfEJHYnXJKKF3dtSv89795uWPKyUQxdWr4m4f/DxHJBYlF/Hr2hA4d4KKL8vauYDmZKKZNC/+fXXaJOxIRqXM+/xz+8IdwuutJJ8HQoXFHlHY52UcxdWpI4HnQRyQiuaKkBG6/PZxq+fbbsGZN3BFlTM4mCnVki0jGzJkTrok45xzYYw+YORNOPTXuqDIm5xJFcXE48lP/hIhkzJw54XqIBx6AF1+Etm3jjiijcq6PYtWq8FdHFCKSVtOmhSJ+J58MRx4ZivhttlncUcUi544oVq4Mf5UoRCQtiorgL38J10JccUVZEb86miQgRxNF69bQvHnckYhI3pk4MVwPMXx4OKNp+nSVfyAHm55WroS99447ChHJO4sXw377hRpNL70EvXvHHVHWyLkjiqIidWSLSC2aPTv8bdkSnnoKPvxQSaKcnEsUoP4JEakF330XbkPaqVO4dzXAEUfAJpvEGlY2yrmmJ9ARhYisp6eegrPPhqVL4bLLoHv3uCPKajmXKDbYALbeOu4oRCRnDRkCDz4YfnG++GLovJakci5RNG8e6jyJiKQssYjfHnvATjvBhReGX55SpbT2UZhZHzObY2ZzzezSCqa3MbPxZjbNzGaY2aFVLbNly/TEKiJ5asGC0Dn90ENheOhQuOQSJYlqSFuiMLP6wO3AIUBH4Dgz61hutr8CT7j7rsBA4I50xSMidczatXDrraGI36RJZUcVUm3pPKLoDsx19/nu/jMwCuhbbh4HNo2eNwW+SGM8IlJXfPRRuODqvPNCMb9Zs0LfhNRIOo+9WgKLEoYLgR7l5rkCeNnM/gg0Bg6saEFmNhQYCtCmTZtaD1RE8szcuaGQ38MPw6BB6thcT+k8oqjoP1P+2O844AF3bwUcCjxsZr+Kyd3vcfcCdy9o0aJFGkIVkZz3/vtw//3h+RFHhL6JE05QkqgF6UwUhUDrhOFW/Lpp6VTgCQB3fwdoBKiKk4ikbtUquPRS6NED/vGPsiJ+m26a/HWSsnQmiveADmbWzswaEDqrx5abZyFwAICZ7URIFEvSGJOI5JMJE8I9ka+9NvRBTJumIn5pkLY+CncvNrNzgJeA+sD97j7LzK4Cprj7WOBC4F4zG0ZolhrirlMTRCQFixfDAQeEctKvvhqeS1pYru2XCwoKfMqUKXGHISJx+fBD2Hnn8Py550LF18aN440pB5jZ++5eUJPX5mRRQBGpg779Fk48Ebp0KSvid/jhShIZoEsTRSS7ucOTT8I558CyZXD55aHjWjJGiUJEstvgweF6iIICeO21smYnyRglChHJPolF/Hr1Cs1N55+v+kwxUR+FiGSX+fPhwAPhgQfC8KmnwkUXKUnESIlCRLLD2rVwyy2haem996Cedk/ZQilaROI3ezaccgq8+y4cdhjcdRe0ahV3VBJRohCR+C1YAPPmwWOPwcCBqs+UZZQoRCQe770H06fD6aeHo4j586FJk7ijkgqoEVBEMmvlytA53bMnDB9eVsRPSSJrKVGISOa88UY41fXGG8ORhIr45QQ1PYlIZhQWwkEHwTbbwOuvhxpNkhN0RCEi6fXBB+Fvq1bw7LMwY4aSRI5RohCR9FiyBI4/Hrp2hTffDOMOPRQ23jjeuKTa1PQkIrXLHUaNgnPPhe+/hyuvhN13jzsqWQ8pJYroDnVt3H1umuMRkVx34onw6KOhwut990GnTnFHJOupyqYnMzsM+BB4JRruamZj0h2YiOSQkpKyQn777Qc33QQTJypJ5IlU+iiuAnoAywHcfTrQPp1BiUgOmTs33Ib0P/8Jw6eeCsOGQf368cYltSaVRLHG3ZeXG5db908VkdpXXAw33BCK+E2bBg0axB2RpEkqfRQfmdkAoJ6ZtQPOAyalNywRyWozZ8LJJ8OUKdC3L9xxB2y9ddxRSZqkckRxDrAbUAI8DRQRkoWI1FULF8Lnn4ezm8aMUZLIc6kcURzs7pcAl5SOMLOjCElDROqKd98NF88NHRquh5g/HzbZJO6oJANSOaL4awXjLqvtQEQkS/30E1xwQbgW4rrrYPXqMF5Jos6o9IjCzA4G+gAtzeymhEmbEpqhRCTfvf56KN43fz6ceSZccw00bBh3VJJhyZqevgFmEvokZiWMXwFcms6gRCQLFBbCwQdDu3ahBMc++8QdkcSk0kTh7tOAaWb2qLsXZTAmEYnTtGmw666hiN+4cdCrF2y0UdxRSYxS6aNoaWajzGyGmX1S+kh7ZCKSWV9/DcceC926lRXx69NHSUJSShQPAP8BDDgEeAIYlcaYRCST3OGRR6BjR3jmGbj6athjj7ijkiySSqLY2N1fAnD3ee7+V0DF5EXyxfHHh0J+O+wQ7mF92WWw4YZxRyVZJJXrKFabmQHzzOwMYDGwZXrDEpG0KikBs/Do3Tuc+nr22arPJBVK5YhiGLAJcC6wJ3A6cEo6gxKRNPrkk1Dh9f77w/DJJ4d7RyhJSCWqPKJw93ejpyuAEwHMrFU6gxKRNCguDuW/L78cGjVSJ7WkLOkRhZn9zsz6mVnzaLiTmT2EigKK5JYZM6BnT7jkEjjkEJg9O/RNiKSg0kRhZsOBR4FBwItmdhkwHvgA2D4z4YlIrSgshEWL4Mkn4amn4Le/jTsiySHJmp76Aru4+yoz2xz4Ihqek+rCzawP8C+gPjDC3a+pYJ4BwBWEe1x84O76mSNSG/73v3AkccYZZUX8GjeOOyrJQcmanorcfRWAu38HfFzNJFEfuJ1w7UVH4Dgz61hung7An4E93b0TcH414xeR8n78Ec47D/baC268sayIn5KE1FCyI4ptzay0lLgBbROGcfejqlh2d2Cuu88HMLNRhKOU2QnznA7c7u7LomV+U834RSTRyy+HMuALF4bTXf/v/1TET9ZbskTRv9zwbdVcdktgUcJwIeHe24m2BzCziYTmqSvc/cXyCzKzocBQgDZt2lQzDJE6YtEiOOww2G47mDAhHFGI1IJkRQFfW89lW0WLrWD9HYB9gVbAW2bWufw9ut39HuAegIKCAt2vWyTR++/DbrtB69bw/POw997h9FeRWpLKBXc1VQi0ThhuRegQLz/Ps+6+xt0XAHMIiUNEqvLVV3DMMVBQUFbE76CDlCSk1qUzUbwHdDCzdmbWABgIjC03zzNEdaOiazW2B+anMSaR3OcODz4YiviNGxf6IVTET9IolVpPAJhZQ3dfner87l5sZucALxH6H+5391lmdhUwxd3HRtN6m9lsYC1wsbsvrd5bEKljBg6EJ56APfeEESNgxx3jjkjynLknb/I3s+7AfUBTd29jZrsAp7n7HzMRYHkFBQU+ZcqUOFYtEp/EIn4PPggrVsBZZ0G9dDYKSD4xs/fdvaAmr03lU3YrcDiwFMDdP0BlxkUy5+OPw21I77svDA8eDOecoyQhGZPKJ62eu39ebtzadAQjIgnWrAn9D7vsEmozbbJJ3BFJHZVKH8WiqPnJo6ut/wjoVqgi6TR9eij/PX06HH00/PvfsNVWcUcldVQqieJMQvNTG+Br4NVonIiky1dfhcdTT8FRVRVBEEmvVBJFsbsPTHskInXd22+HIn5nnQV9+sC8ebDxxnFHJZJSH8V7Zva8mQ02syZpj0ikrlmxInRO77033HJLWRE/JQnJElUmCnffDrga2A340MyeMTMdYYjUhpdegs6d4Y47QsXXqVNVxE+yTkrn17n7/9z9XKAb8APhhkYisj4WLYLDDw9HDm+/HY4mdGaTZKEqE4WZbWJmg8xsHDAZWAKoXoBITbjD5MnheevW8MILMG2aSnBIVkvliGIm0BO4zt3bu/uF7v5umuMSyT9ffgn9+0OPHmVF/A48UEX8JOulctbTtu5ekvZIRPKVOzzwAFxwARQVwbXXhjpNIjmi0kRhZje6+4XAU2b2q4JQKdzhTkQABgyA0aPDWU0jRsD228cdkUi1JDuieDz6W90724nI2rWhgF+9enDEEbD//vCHP6g+k+SkSj+17h71uLGTu7+W+AB2ykx4Ijnoo4/C0UNpEb+TToIzz1SSkJyVyif3lArGnVrbgYjkvDVr4OqroWtXmDMHmjaNOyKRWpGsj+JYwl3p2pnZ0wmTmgDLK36VSB01bRoMGRJKcBx7LNx6K2y5ZdxRidSKZH0Ukwn3oGgF3J4wfgUwLZ1BieScr7+Gb7+FZ56Bvn3jjkakVlWaKNx9AbCAUC1WRMqbMAE+/BDOPjsU8Zs7FzbaKO6oRGpdpX0UZvZm9HeZmX2X8FhmZt9lLkSRLPPDD6HCa69eoYmptIifkoTkqWSd2aW3O20OtEh4lA6L1D3PPw+dOsHdd4cL6FTET+qAZKfHll6N3Rqo7+5rgd2BPwCNMxCbSHZZtCj0PzRtCv/7H9x4IzTWV0HyXyqnxz5DuA3qdsBDhGsoHktrVCLZwh0mTQrPW7eGl18ORxE9esQbl0gGpZIoStx9DXAUcIu7/xFomd6wRLLAF19Av36w++5lRfz22w8aNIg3LpEMSyVRFJvZMcCJwHPRuA3TF5JIzNxDTaaOHcMRxA03qIif1GmpVI89BTiLUGZ8vpm1A0amNyyRGB19NDz9dDiracQIaN8+7ohEYlVlonD3mWZ2LtDezHYE5rr7P9MfmkgGJRbx69cPeveG009XfSYRUrvD3d7AXOA+4H7gEzPTcbjkj5kzQ9NSaRG/E09UpVeRBKl8E24GDnX3Pd19D+Aw4F/pDUskA37+Ga68Erp1g3nzoFmzuCMSyUqp9FE0cPfZpQPu/pGZ6bQPyW3vvx+K+M2cCccfD7fcAi10HalIRVJJFFPN7G7g4Wh4ECoKKLlu6VJYvhzGjYPDD487GpGslkqiOAM4F/gTYMAE4N/pDEokLcaPD0X8zj03dFZ/+ik0ahR3VCJZL2miMLOdge2AMe5+XWZCEqll338Pf/oT3HMP7Lhj6Khu2FBJQiRFyarH/oVQvmMQ8IqZVXSnO5HsNm5cuHBuxAi46KLQN6EifiLVkuyIYhDQxd1/MrMWwPOE02NFcsOiRdC/fziKeOYZ+N3v4o5IJCclOz12tbv/BODuS6qYVyQ7uIfKrlBWxG/KFCUJkfWQbOe/rZk9HT3GANslDD+d5HW/MLM+ZjbHzOaa2aVJ5jvazNzMCqr7BkR+UVgIRx4ZLp4rLeK3774q4ieynpI1PfUvN3xbdRZsZvUJ99o+CCgE3jOzsYnXZETzNSGcVfVudZYv8ouSErj3Xrj4Yiguhptugr32ijsqkbyR7J7Zr63nsrsT6kLNBzCzUUBfYHa5+f4BXAdctJ7rk7qqf//QB7H//iFhbLtt3BGJ5JV09ju0BBYlDBdS7j4WZrYr0NrdnyMJMxtqZlPMbMqSJUtqP1LJPcXF4UgCQqK491549VUlCZE0SGeisArG+S8TzeoR6khdWNWC3P0edy9w94IWKrMgM2aEmwnde28YPuEEOO20UP1VRGpdyonCzKp78nkh4X7bpVoBXyQMNwE6A2+Y2WdAT2CsOrSlUqtXw+WXw267weefqzaTSIakUma8u5l9CHwaDe9iZqmU8HgP6GBm7aIiggOBsaUT3f17d2/u7m3dvS0wCTjS3afU5I1InnvvvVDl9aqr4Ljj4KOP4Kij4o5KpE5I5YjiVuBwYCmAu38A7FfVi9y9GDgHeAn4CHjC3WeZ2VVmdmTNQ5Y6adky+PFHeP55eOgh2GKLuCMSqTNSKQpYz90/t3Xbf9emsnB3f55wRXfiuL9XMu++qSxT6pDXXw9F/M47LxTx++QTld8QiUEqRxSLzKw74GZW38zOBz5Jc1xSly1fHm5DesABcPfdoW8ClCREYpJKojgTuABoA3xN6HQ+M51BSR327LOhiN/994eKryriJxK7Kpue3P0bQke0SHotXAjHHAM77QRjx0KBToATyQZVJgozu5eE6x9KufvQtEQkdYs7vP027L03tGkTLprr2VP1mUSySCpNT68Cr0WPicCWwOp0BiV1xMKFcNhhsM8+ZUX89tlHSUIky6TS9PR44rCZPQy8kraIJP+VlMBdd8Ell4QjiltvVRE/kSyWyumx5bUDtqntQKQOOeqo0Gl90EHh9qRt28YdkYgkkUofxTLK+ijqAd8Bld5bQqRCxcVQr154HHss9O0LQ4aoPpNIDkiaKCxcZbcLsDgaVeLuv+rYFknqgw/glFOFRq9GAAAUDklEQVTCtRFnnBFKcIhIzkjamR0lhTHuvjZ6KElI6oqK4K9/Dae5FhbCVlvFHZGI1EAqZz1NNrNuaY9E8svkybDrrvDPf8KgQaGIX79+cUclIjVQadOTmW0QFfbbCzjdzOYBPxHuM+HuruQhlfvhB1i1Cl58EQ4+OO5oRGQ9JOujmAx0A/QzUFLz8sswaxYMGwYHHghz5qj8hkgeSJYoDMDd52UoFslVy5bBBRfAAw9Ap05w1lkhQShJiOSFZImihZldUNlEd78pDfFIrnn6aTj7bFiyBP78Z/j735UgRPJMskRRH9iEiu99LRJKcAwcCJ07hxsK7bpr3BGJSBokSxRfuvtVGYtEcoM7TJgAvXqFIn6vvw49esCGG8YdmYikSbLTY3UkIev6/HM45BDYd9+yIn577aUkIZLnkiWKAzIWhWS3khK47bbQUf322/Dvf4ey4CJSJ1Ta9OTu32UyEMli/frBuHHheoi774ZtVBNSpC6pSfVYqQvWrIH69UMRv+OOg6OPhhNPVBE/kToolRIeUtdMnQrdu4d7RkBIFCedpCQhUkcpUUiZVavCtRDdu8NXX0Hr1nFHJCJZQE1PEkyaBIMHwyefhJLgN9wAzZrFHZWIZAElCgl++in0S7zySqjTJCISUaKoy158MRTxu/BCOOAA+PhjaNAg7qhEJMuoj6IuWro0NDMdcgg8+CD8/HMYryQhIhVQoqhL3GH0aOjYER57LNx97r33lCBEJCk1PdUlCxfC8cdDly7h3hG77BJ3RCKSA3REke/cQ+E+CFdUv/FGOMNJSUJEUqREkc8WLIDevUNHdWkRvz32gA10ICkiqVOiyEdr18K//hXuE/Huu3DnnSriJyI1pp+W+ahvX/jvf+HQQ0MZDl1hLSLrQYkiXyQW8TvxxFCf6fjjVZ9JRNZbWpuezKyPmc0xs7lmdmkF0y8ws9lmNsPMXjMz1a+uiSlToKAgNDEBHHssDBqkJCEitSJticLM6gO3A4cAHYHjzKxjudmmAQXu3gUYDVyXrnjy0qpVcMkl4VakS5boPhEikhbpPKLoDsx19/nu/jMwCuibOIO7j3f3ldHgJKBVGuPJL++8E05xve66UMRv9mw4/PC4oxKRPJTOPoqWwKKE4UKgR5L5TwVeqGiCmQ0FhgK0adOmtuLLbatWhVuUvvpqOP1VRCRN0pkoKmog9wpnNDsBKAB6VTTd3e8B7gEoKCiocBl1wvPPhyJ+F18M++8PH30EG24Yd1QikufS2fRUCCSel9kK+KL8TGZ2IHAZcKS7r05jPLnr22/hhBPgsMPg0UfLivgpSYhIBqQzUbwHdDCzdmbWABgIjE2cwcx2Be4mJIlv0hhLbnKHUaNgp53giSfg8sth8mQV8RORjEpb05O7F5vZOcBLQH3gfnefZWZXAVPcfSxwPbAJ8KSFUzkXuvuR6Yop5yxcGMqB77IL3Hcf7Lxz3BGJSB1k7rnV5F9QUOBTpkyJO4z0cYfXXiu7y9ykSfC734WL6UREasjM3nf3gpq8VrWessm8eeEMpoMOKivi17OnkoSIxEqJIhusXQs33RSalt5/H+6+W0X8RCRrqNZTNjjiCHjhhXDB3J13Qitddygi2UOJIi4//xzuC1GvHgwZEgr5DRyo+kwiknXU9BSHyZNht93gjjvC8IABodqrkoSIZCElikxauRIuvBB23x2WLYPttos7IhGRKqnpKVPefjtcEzF/PvzhD3DttdC0adxRiYhUSYkiU0pvLDR+POy7b9zRiIikTIkincaNC4X7/vQn2G+/UAp8A21yEckt6qNIhyVLwm1IjzwSRo4sK+KnJCEiOUiJoja5w2OPhSJ+o0fDVVfBu++qiJ+I5DT9xK1NCxfCySfDrruGIn6dOsUdkYjIetMRxfoqKYGXXgrPt9kG3noLJk5UkhCRvKFEsT4+/TTcaa5PH5gwIYzr3l1F/EQkryhR1ERxMVx/PXTpAtOnh2YmFfETkTylPoqaOPzw0NzUt28ow7H11nFHJJKV1qxZQ2FhIUVFRXGHUmc0atSIVq1asWEt3ipZiSJVq1eHe1TXqwennQannALHHKP6TCJJFBYW0qRJE9q2bYvpu5J27s7SpUspLCykXbt2tbZcNT2lYtIk6NYNbr89DB99dCjkpw++SFJFRUVsscUWShIZYmZsscUWtX4Ep0SRzE8/wbBhsMcesGIFdOgQd0QiOUdJIrPSsb3V9FSZt94KRfwWLICzzoLhw2HTTeOOSkQk43REUZni4tAn8eaboclJSUIkZ40ZMwYz4+OPP/5l3BtvvMHhhx++znxDhgxh9OjRQOiIv/TSS+nQoQOdO3eme/fuvPDCC+sdy/Dhw2nfvj077LADL5Veg1XO66+/Trdu3ejcuTODBw+muLgYgOuvv56uXbvStWtXOnfuTP369fnuu+/WO6aqKFEkeuaZcOQAoYjfrFmwzz7xxiQi623kyJHstddejBo1KuXX/O1vf+PLL79k5syZzJw5k3HjxrFixYr1imP27NmMGjWKWbNm8eKLL3LWWWexdu3adeYpKSlh8ODBjBo1ipkzZ7LNNtvw4IMPAnDxxRczffp0pk+fzvDhw+nVqxebb775esWUCjU9AXz9Nfzxj/Dkk6HT+sILQ30mFfETqTXnnx8uO6pNXbvCLbckn+fHH39k4sSJjB8/niOPPJIrrriiyuWuXLmSe++9lwULFtCwYUMAfvOb3zBgwID1ivfZZ59l4MCBNGzYkHbt2tG+fXsmT57M7rvv/ss8S5cupWHDhmy//fYAHHTQQQwfPpxTTz11nWWNHDmS4447br3iSVXdPqJwh4cfho4d4dln4Z//DGc4qYifSN545pln6NOnD9tvvz2bb745U6dOrfI1c+fOpU2bNmyaQpPzsGHDfmkOSnxcc801v5p38eLFtG7d+pfhVq1asXjx4nXmad68OWvWrGHKlCkAjB49mkWLFq0zz8qVK3nxxRfp379/lfHVhrr9k3nhwnBNREFBuLp6xx3jjkgkb1X1yz9dRo4cyfnnnw/AwIEDGTlyJN26dav07KDqnjV08803pzyvu1e5PjNj1KhRDBs2jNWrV9O7d282KNe6MW7cOPbcc8+MNDtBXUwUpUX8DjkkFPGbODFUe1V9JpG8s3TpUl5//XVmzpyJmbF27VrMjOuuu44tttiCZcuWrTP/d999R/PmzWnfvj0LFy5kxYoVNGnSJOk6hg0bxvjx4381fuDAgVx66aXrjGvVqtU6RweFhYVsXUFlh91335233noLgJdffplPPvlknemjRo3KWLMTEDJcLj122203r7E5c9z33tsd3N94o+bLEZGUzJ49O9b133XXXT506NB1xu2zzz4+YcIELyoq8rZt2/4S42effeZt2rTx5cuXu7v7xRdf7EOGDPHVq1e7u/sXX3zhDz/88HrFM3PmTO/SpYsXFRX5/PnzvV27dl5cXPyr+b7++mt3dy8qKvL999/fX3vttV+mLV++3Js1a+Y//vhjpeupaLsDU7yG+9260UdRXAzXXhuK+H34IfznPzqbSaQOGDlyJL///e/XGde/f38ee+wxGjZsyCOPPMLJJ59M165dOfrooxkxYgRNmzYF4Oqrr6ZFixZ07NiRzp07069fP1q0aLFe8XTq1IkBAwbQsWNH+vTpw+233079qDXj0EMP5YsvvgDCabA77bQTXbp04YgjjmD//ff/ZRljxoyhd+/eNG7ceL1iqQ7zCtrMsllBQYGXdvKk7OCD4eWX4aijwjURW22VnuBEZB0fffQRO+20U9xh1DkVbXcze9/dC2qyvPztoygqChfM1a8PQ4eGR4bOEBARySf52fQ0cWI4wbq0iF///koSIiI1lF+J4scf4dxzw02EiopAh7wiscu15u1cl47tnT+J4s03oXNnuO02OOccmDkTDjoo7qhE6rRGjRqxdOlSJYsM8eh+FI0aNarV5eZXH8XGG4eqr3vuGXckIkK4bqCwsJAlS5bEHUqdUXqHu9qU24ni6afh44/hL3+BXr3Cqa+6cE4ka2y44Ya1eqc1iUdam57MrI+ZzTGzuWZ2aQXTG5rZ49H0d82sbUoL/uqrcJe5/v1hzBj4+ecwXklCRKTWpS1RmFl94HbgEKAjcJyZdSw326nAMndvD9wMXFvlgpcuDZ3Uzz0XSoL/738q4icikkbpPKLoDsx19/nu/jMwCuhbbp6+wIPR89HAAVZVRa7PPw+d1h98AJdeGq6VEBGRtElnH0VLILE2biHQo7J53L3YzL4HtgC+TZzJzIYCQ6PB1fb22zNV6RWA5pTbVnWYtkUZbYsy2hZldqjpC9OZKCo6Mih/jlwq8+Du9wD3AJjZlJpehp5vtC3KaFuU0bYoo21RxsyqWfuoTDqbngqB1gnDrYAvKpvHzDYAmgLpvwGsiIikLJ2J4j2gg5m1M7MGwEBgbLl5xgKDo+dHA6+7rswREckqaWt6ivoczgFeAuoD97v7LDO7ilAXfSxwH/Cwmc0lHEkMTGHR96Qr5hykbVFG26KMtkUZbYsyNd4WOVdmXEREMit/aj2JiEhaKFGIiEhSWZso0lb+IwelsC0uMLPZZjbDzF4zs23iiDMTqtoWCfMdbWZuZnl7amQq28LMBkSfjVlm9limY8yUFL4jbcxsvJlNi74nh8YRZ7qZ2f1m9o2ZzaxkupnZrdF2mmFm3VJacE1vtp3OB6Hzex6wLdAA+ADoWG6es4C7oucDgcfjjjvGbbEfsHH0/My6vC2i+ZoAE4BJQEHcccf4uegATAOaRcNbxh13jNviHuDM6HlH4LO4407TttgH6AbMrGT6ocALhGvYegLvprLcbD2iSE/5j9xU5bZw9/HuvjIanES4ZiUfpfK5APgHcB1QlMngMiyVbXE6cLu7LwNw928yHGOmpLItHNg0et6UX1/TlRfcfQLJr0XrCzzkwSRgMzP7bVXLzdZEUVH5j5aVzePuxUBp+Y98k8q2SHQq4RdDPqpyW5jZrkBrd38uk4HFIJXPxfbA9mY20cwmmVmfjEWXWalsiyuAE8ysEHge+GNmQss61d2fANl7P4paK/+RB1J+n2Z2AlAA9EprRPFJui3MrB6hCvGQTAUUo1Q+FxsQmp/2JRxlvmVmnd19eZpjy7RUtsVxwAPufqOZ7U64fquzu5ekP7ysUqP9ZrYeUaj8R5lUtgVmdiBwGXCku6/OUGyZVtW2aAJ0Bt4ws88IbbBj87RDO9XvyLPuvsbdFwBzCIkj36SyLU4FngBw93eARoSCgXVNSvuT8rI1Uaj8R5kqt0XU3HI3IUnkazs0VLEt3P17d2/u7m3dvS2hv+ZId69xMbQslsp35BnCiQ6YWXNCU9T8jEaZGalsi4XAAQBmthMhUdTF+7OOBU6Kzn7qCXzv7l9W9aKsbHry9JX/yDkpbovrgU2AJ6P+/IXufmRsQadJituiTkhxW7wE9Daz2cBa4GJ3Xxpf1OmR4ra4ELjXzIYRmlqG5OMPSzMbSWhqbB71x1wObAjg7ncR+mcOBeYCK4GTU1puHm4rERGpRdna9CQiIllCiUJERJJSohARkaSUKEREJCklChERSUqJQrKOma01s+kJj7ZJ5m1bWaXMaq7zjaj66AdRyYsdarCMM8zspOj5EDPbOmHaCDPrWMtxvmdmXVN4zflmtvH6rlvqLiUKyUar3L1rwuOzDK13kLvvQig2eX11X+zud7n7Q9HgEGDrhGmnufvsWomyLM47SC3O8wElCqkxJQrJCdGRw1tmNjV67FHBPJ3MbHJ0FDLDzDpE409IGH+3mdWvYnUTgPbRaw+I7mHwYVTrv2E0/horuwfIDdG4K8zsIjM7mlBz69FonRtFRwIFZnammV2XEPMQM/t3DeN8h4SCbmZ2p5lNsXDviSujcecSEtZ4MxsfjettZu9E2/FJM9ukivVIHadEIdloo4RmpzHRuG+Ag9y9G3AscGsFrzsD+Je7dyXsqAujcg3HAntG49cCg6pY/xHAh2bWCHgAONbddyZUMjjTzDYHfg90cvcuwNWJL3b30cAUwi//ru6+KmHyaOCohOFjgcdrGGcfQpmOUpe5ewHQBehlZl3c/VZCLZ/93H2/qJTHX4EDo205BbigivVIHZeVJTykzlsV7SwTbQjcFrXJryXULSrvHeAyM2sFPO3un5rZAcBuwHtReZONCEmnIo+a2SrgM0IZ6h2ABe7+STT9QeBs4DbCvS5GmNl/gZRLmrv7EjObH9XZ+TRax8RoudWJszGhXEXiHcoGmNlQwvf6t4Qb9Mwo99qe0fiJ0XoaELabSKWUKCRXDAO+BnYhHAn/6qZE7v6Ymb0LHAa8ZGanEcoqP+juf05hHYMSCwiaWYX3N4lqC3UnFJkbCJwD7F+N9/I4MAD4GBjj7m5hr51ynIS7uF0D3A4cZWbtgIuA37n7MjN7gFD4rjwDXnH346oRr9RxanqSXNEU+DK6f8CJhF/T6zCzbYH5UXPLWEITzGvA0Wa2ZTTP5pb6PcU/BtqaWfto+ETgzahNv6m7P0/oKK7ozKMVhLLnFXka6Ee4R8Lj0bhqxenuawhNSD2jZqtNgZ+A783sN8AhlcQyCdiz9D2Z2cZmVtHRmcgvlCgkV9wBDDazSYRmp58qmOdYYKaZTQd2JNzycTZhh/qymc0AXiE0y1TJ3YsI1TWfNLMPgRLgLsJO97loeW8SjnbKewC4q7Qzu9xylwGzgW3cfXI0rtpxRn0fNwIXufsHhPtjzwLuJzRnlboHeMHMxrv7EsIZWSOj9UwibCuRSql6rIiIJKUjChERSUqJQkREklKiEBGRpJQoREQkKSUKERFJSolCRESSUqIQEZGk/h+pKKCk4eTXUgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2149f12c240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT ROC curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test new data\n",
    "example_measures=np.array([15.44,12.54,150.9,998,0.2345,0.3452,0.2891,0.1234,0.3421,0.06879,2.076,0.8079,7.274,168.7,0.009786,0.03804,0.04372,0.02785,0.02002,0.007621,28.75,16.44,192.7,2025,0.1723,0.7752,0.7121,0.3421,0.4802,0.1278\n",
    "])\n",
    "example_measures = example_measures.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(example_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gopia\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.linear_model.logistic module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\gopia\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#Perform Logistic Regression\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "\n",
    "cls =LogisticRegression(random_state =0)\n",
    "\n",
    "lr_cls=cls.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting on test and train data\n",
    "lr_y_test =lr_cls.predict(x_test)\n",
    "lr_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual breast cancer : \n",
      "[1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 1 0 1\n",
      " 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0\n",
      " 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual breast cancer : \")\n",
    "print(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted breast cancer : \n",
      "[1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 1 0 1\n",
      " 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0\n",
      " 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPredicted breast cancer : \")\n",
    "print(lr_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_y_train = lr_cls.predict(x_train)\n",
    "lr_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy score: 94.736842\n",
      "Recall score : 92.500000\n",
      "ROC score : 94.222973\n",
      "\n",
      "[[71  3]\n",
      " [ 3 37]]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score on Test and Train\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "print(\"\\nAccuracy score: %f\" %(accuracy_score(y_test,lr_y_test) * 100))\n",
    "print(\"Recall score : %f\" %(recall_score(y_test, lr_y_test) * 100))\n",
    "print(\"ROC score : %f\\n\" %(roc_auc_score(y_test, lr_y_test) * 100))\n",
    "print(confusion_matrix(y_test, lr_y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data1[['radius_mean', 'texture_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'symmetry_mean', 'fractal_dimension_mean']]\n",
    "y = data1['diagnosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "lr_acc = cross_val_score(lr_cls, X_train_std, y_train, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "lr_proba = cross_val_predict(lr_cls, X_train_std, y_train, cv=3, method='predict_proba')\n",
    "lr_scores = lr_proba[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94736842, 0.93421053, 0.9205298 ])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5934065934065934"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_accu_train= accuracy_score(y_train,lr_y_train)  #train 98--rs=50  \n",
    "lr_accu_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def ROC_curve(title, y_train, scores, label=None):\n",
    "    \n",
    "    # calculate the ROC score\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, scores)\n",
    "    print('AUC Score ({}): {:.2f} '.format(title, roc_auc_score(y_train, scores)))\n",
    "\n",
    "    # plot the ROC curve\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label, color='b')\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "    plt.title('ROC Curve: {}'.format(title), fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "roc_curve() missing 1 required positional argument: 'scores'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-94eef6bf77fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Plot ROC Curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mROC_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'logistic regression'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-81-7a13ebb3a5af>\u001b[0m in \u001b[0;36mROC_curve\u001b[1;34m(title, y_train, scores, label)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# calculate the ROC score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'AUC Score ({}): {:.2f} '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: roc_curve() missing 1 required positional argument: 'scores'"
     ]
    }
   ],
   "source": [
    "#Plot ROC Curve\n",
    "ROC_curve('logistic regression', y_train, lr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.947368421053\n",
      "0.958300691647\n"
     ]
    }
   ],
   "source": [
    "#Precision score on Test and Train\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "lr_precision_test =precision_score(y_test, lr_y_test, average='weighted')  \n",
    "print(lr_precision_test)\n",
    "lr_precision_train =precision_score(y_train, lr_y_train, average='weighted')\n",
    "print(lr_precision_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perform Naibe Bayes Classification\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_classfier =GaussianNB()\n",
    "nb_classfier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting on Test and Train\n",
    "nb_y_test = nb_classfier.predict(x_test)  #for test\n",
    "nb_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_y_train=nb_classfier.predict(x_train)#for train\n",
    "nb_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49, 22],\n",
       "       [36,  7]], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build confusion matrix on Test and Train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "nb_cm_test = confusion_matrix(y_test,nb_y_test)\n",
    "nb_cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49122807017543857"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy score on Test and Train\n",
    "from sklearn.metrics import accuracy_score\n",
    "nb_acc_test=accuracy_score(y_test, nb_y_test)\n",
    "nb_acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6175824175824176"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_acc_train=accuracy_score(y_train, nb_y_train)  #train  \n",
    "nb_acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45007650973274965\n",
      "0.5977150775191059\n"
     ]
    }
   ],
   "source": [
    "#Precision score on Test and Train\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "nb_precision_test =precision_score(y_test, nb_y_test, average='weighted')  \n",
    "print(nb_precision_test)\n",
    "nb_precision_train =precision_score(y_train, nb_y_train, average='weighted')\n",
    "print(nb_precision_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Classification\n",
    "from sklearn.svm import SVC\n",
    "sc = SVC(kernel='rbf')\n",
    "sc_classifier = sc.fit(x_train,y_train)  #model building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign']\n"
     ]
    }
   ],
   "source": [
    "#Predicting on Test and Train data\n",
    "svc_y_test = sc_classifier.predict(x_test)\n",
    "print(svc_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Malignant' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign' 'Malignant'\n",
      " 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign' 'Malignant' 'Malignant'\n",
      " 'Benign' 'Benign' 'Malignant' 'Malignant' 'Benign' 'Malignant' 'Benign'\n",
      " 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant' 'Benign'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign' 'Malignant'\n",
      " 'Malignant' 'Benign' 'Benign' 'Benign' 'Malignant' 'Malignant'\n",
      " 'Malignant' 'Malignant' 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant' 'Benign' 'Malignant'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign' 'Malignant'\n",
      " 'Malignant' 'Benign' 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign'\n",
      " 'Malignant' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign' 'Malignant'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign' 'Malignant' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant'\n",
      " 'Benign' 'Benign' 'Benign' 'Malignant' 'Benign' 'Malignant' 'Malignant'\n",
      " 'Benign' 'Benign' 'Malignant' 'Malignant' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign' 'Malignant' 'Malignant'\n",
      " 'Benign' 'Benign' 'Malignant' 'Benign' 'Malignant' 'Malignant' 'Benign'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Malignant' 'Benign' 'Benign' 'Benign'\n",
      " 'Malignant' 'Malignant' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Malignant' 'Malignant' 'Benign' 'Benign' 'Benign'\n",
      " 'Malignant' 'Malignant' 'Benign' 'Benign' 'Malignant' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant' 'Benign' 'Benign'\n",
      " 'Benign' 'Malignant' 'Malignant' 'Malignant' 'Malignant' 'Malignant'\n",
      " 'Benign' 'Malignant' 'Benign' 'Malignant' 'Malignant' 'Benign' 'Benign'\n",
      " 'Benign' 'Malignant' 'Benign' 'Benign' 'Malignant' 'Benign' 'Benign'\n",
      " 'Malignant' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign' 'Malignant' 'Benign'\n",
      " 'Benign' 'Benign' 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign'\n",
      " 'Benign' 'Malignant' 'Malignant' 'Benign' 'Malignant' 'Malignant'\n",
      " 'Benign' 'Malignant' 'Benign' 'Malignant' 'Benign' 'Malignant' 'Benign'\n",
      " 'Benign' 'Malignant' 'Malignant' 'Malignant' 'Benign' 'Malignant'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign' 'Malignant'\n",
      " 'Malignant' 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant' 'Malignant'\n",
      " 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Malignant' 'Benign' 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Malignant' 'Malignant' 'Malignant' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Malignant' 'Benign' 'Benign' 'Malignant' 'Malignant' 'Malignant'\n",
      " 'Benign' 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign' 'Malignant'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign' 'Malignant'\n",
      " 'Benign' 'Malignant' 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign'\n",
      " 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign' 'Malignant' 'Benign'\n",
      " 'Malignant' 'Malignant' 'Benign' 'Malignant' 'Malignant' 'Benign'\n",
      " 'Benign' 'Benign' 'Malignant' 'Malignant' 'Malignant' 'Benign'\n",
      " 'Malignant' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign' 'Malignant' 'Malignant'\n",
      " 'Malignant' 'Benign' 'Benign' 'Malignant' 'Benign' 'Malignant' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant' 'Benign'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Malignant' 'Benign' 'Malignant'\n",
      " 'Malignant' 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant'\n",
      " 'Malignant' 'Malignant' 'Benign' 'Benign' 'Malignant' 'Malignant'\n",
      " 'Benign' 'Malignant' 'Malignant' 'Benign' 'Benign' 'Malignant' 'Benign'\n",
      " 'Benign' 'Malignant' 'Benign' 'Malignant' 'Malignant' 'Benign' 'Benign'\n",
      " 'Benign' 'Malignant' 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign'\n",
      " 'Malignant' 'Malignant' 'Malignant' 'Benign' 'Malignant' 'Benign'\n",
      " 'Malignant' 'Malignant' 'Benign' 'Malignant' 'Malignant' 'Benign'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Malignant' 'Benign' 'Benign'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Malignant' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant' 'Benign' 'Benign'\n",
      " 'Malignant']\n"
     ]
    }
   ],
   "source": [
    "svc_y_train=sc_classifier.predict(x_train)  #train\n",
    "print(svc_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70,  0],\n",
       "       [44,  0]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build confusion matrix on test and train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "svc_cm_test = confusion_matrix(y_test,svc_y_test)   \n",
    "svc_cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[287,   0],\n",
       "       [  0, 168]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_cm_train =confusion_matrix(y_train, svc_y_train)\n",
    "svc_cm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.631578947368421"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy classsification score\n",
    "from sklearn.metrics import accuracy_score\n",
    "svc_acc_test=accuracy_score(y_test, svc_y_test)  #for test  \n",
    "svc_acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_acc_train= accuracy_score(y_train, svc_y_train)  #for train  \n",
    "svc_acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.432825484765\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#Precision score on Test and Train\n",
    "from sklearn.metrics import precision_score\n",
    "sv_precision_test= precision_score(y_test, svc_y_test, average='weighted')  \n",
    "print(sv_precision_test)\n",
    "sv_precision_train=precision_score(y_train, svc_y_train, average='weighted')\n",
    "print(sv_precision_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Calssifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc_clf = DecisionTreeClassifier()\n",
    "dtc_clf.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting on test and train data\n",
    "dtc_y_test =dtc_clf.predict(x_test)\n",
    "dtc_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_y_train = dtc_clf.predict(x_train)\n",
    "dtc_y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[69,  1],\n",
       "       [ 6, 38]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build confusion matrix on Test and Train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "dtc_cm_test = confusion_matrix(y_test, dtc_y_test)\n",
    "dtc_cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9385964912280702"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy score on Test and Train\n",
    "from sklearn.metrics import accuracy_score\n",
    "dtc_accu_test= accuracy_score(y_test,dtc_y_test)\n",
    "dtc_accu_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_accu_train= accuracy_score(y_train,dtc_y_train)    \n",
    "dtc_accu_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.566131237184\n",
      "0.534705542136\n"
     ]
    }
   ],
   "source": [
    "#Precision score on Test and Train\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "dtc_precision_test =precision_score(y_test, dtc_y_test, average='weighted')  \n",
    "print(dtc_precision_test)\n",
    "dtc_precision_train =precision_score(y_train, dtc_y_train, average='weighted')\n",
    "print(dtc_precision_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.552631578947\n",
      "0.536263736264\n"
     ]
    }
   ],
   "source": [
    "#Recall score on Test and Train\n",
    "from sklearn.metrics import recall_score\n",
    "dtc_recall_test=recall_score(y_test,dtc_y_test, average='weighted' )\n",
    "print(dtc_recall_test)\n",
    "dtc_recall_train=recall_score(y_train,dtc_y_train, average='weighted' )\n",
    "print(dtc_recall_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Random Forest Calssifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rmf = RandomForestClassifier(max_depth=3, random_state=0)\n",
    "rf_classi = rmf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting on test and train data\n",
    "rf_y_test = rf_classi.predict(x_test)\n",
    "rf_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_y_train = rf_classi.predict(x_train)\n",
    "rf_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[67,  3],\n",
       "       [ 9, 35]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build Confusion Matrix on Test and Train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "rf_cm_test = confusion_matrix(y_test, rf_y_test)\n",
    "rf_cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[285,   2],\n",
       "       [ 13, 155]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cm_train = confusion_matrix(y_train, rf_y_train)\n",
    "rf_cm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8947368421052632"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy Score on Test and Train\n",
    "from sklearn.metrics import accuracy_score\n",
    "rf_accu_test= accuracy_score(y_test,rf_y_test)  #test\n",
    "rf_accu_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.967032967032967"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_accu_train= accuracy_score(y_train,rf_y_train)  \n",
    "rf_accu_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.949023393728\n",
      "0.971489104116\n"
     ]
    }
   ],
   "source": [
    "#Precision Score on Test and Train\n",
    "from sklearn.metrics import precision_score\n",
    "rf_precision_test =precision_score(y_test, rf_y_test, average='weighted')  \n",
    "print(rf_precision_test)  #test data\n",
    "rf_precision_train =precision_score(y_train, rf_y_train, average='weighted')\n",
    "print(rf_precision_train) #train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.947368421053\n",
      "0.971428571429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "rf_recall_test=recall_score(y_test,rf_y_test, average='weighted' )\n",
    "print(rf_recall_test)\n",
    "rf_recall_train=recall_score(y_train,rf_y_train, average='weighted' )\n",
    "print(rf_recall_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform AdaBoost\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "seed = 7\n",
    "num_trees = 30\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n",
    "results = model_selection.cross_val_score(model, x_train, y_train, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.93478261  0.89130435  0.91304348  0.97826087  0.97826087  0.95555556\n",
      "  0.95555556  0.97777778  0.97777778  1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956231884058\n"
     ]
    }
   ],
   "source": [
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
